{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies go here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Float \n",
    "from config import pw, gkey\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the `minneapolis_housing` database and related tables in Postgresql, using SQLalchemy:\n",
    "\n",
    "* `neighborhood`\n",
    "* `home_value`\n",
    "* `crime`\n",
    "\n",
    "Code for setting up the tables directly in Postgres can be found in the queries.sql file accompanying this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = f\"postgres:{pw}@localhost:5432/minneapolis_housing\"\n",
    "engine = create_engine(f'postgresql://{conn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables if they exist\n",
    "# Neighborhood.__table__.drop(engine)\n",
    "# Crime.__table__.drop(engine)\n",
    "# Home_Value.__table__.drop(engine)\n",
    "# OR \n",
    "# Base.metadata.drop_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base for later creating neighborhood table\n",
    "class Neighborhood(Base):\n",
    "    __tablename__ = 'neighborhood'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood = Column(String(255))\n",
    "    population_2010 = Column(Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base for later creating crime table\n",
    "class Crime(Base):\n",
    "    __tablename__ = 'crime'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood_id = Column(Integer)\n",
    "    crime_description = Column(String(255))\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Home_Value(Base):\n",
    "    __tablename__ = 'home_value'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood_id = Column(Integer)\n",
    "    property_type = Column(String(255))\n",
    "    num_bedrooms = Column(Integer)\n",
    "    sq_footage_house = Column(Integer)\n",
    "    sq_footage_parcel = Column(Integer)\n",
    "    address = Column(String(255))\n",
    "    landuse = Column(String(255))\n",
    "    value_total = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "### Neighborhood datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis city dataset for neighborhoods\n",
    "n_path = os.path.join('.', 'data', 'Minneapolis_Neighborhoods.csv')\n",
    "neighborhood = pd.read_csv(n_path)\n",
    "neighborhood_df = neighborhood[['FID', 'BDNAME']].copy()\n",
    "neighborhood_df.rename(columns={\n",
    "    'FID': 'id',\n",
    "    'BDNAME': 'neighborhood'\n",
    "}, inplace=True)\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "Noticed there wasn't a codebook that explained what the cryptic column names mean, so used FID based on the fact\n",
    "that it is a unique ID.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis neighborhood census dataset \n",
    "census_path = os.path.join('.', 'data', 'census_2010.xls')\n",
    "census = pd.read_excel(census_path, header=None)\n",
    "census_df = census.iloc[6:, :2]\n",
    "census_df.rename(columns={\n",
    "    0: 'neighborhood',\n",
    "    1: 'population_2010'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dfs together into one neighborhood df\n",
    "neighborhoods = neighborhood_df.merge(census_df, how='outer', on='neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for null values\n",
    "mask = pd.isnull(neighborhoods.id)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "mask = pd.isnull(neighborhoods.population_2010)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "# No population data for South Uptown (44) or Kenwood (74)\n",
    "# No ids for CARAG (87) or Kenwood (88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with null values \n",
    "\n",
    "# Kenwood (74) should be updated with Kenwood (88)'s pop data \n",
    "neighborhoods.loc[73, 'population_2010'] = neighborhoods.loc[88, 'population_2010']\n",
    "neighborhoods.tail(20)\n",
    "\n",
    "# create id for CARAG (87)\n",
    "neighborhoods.loc[87, 'id'] = '88'\n",
    "\n",
    "# Drop rows 88, 89\n",
    "neighborhoods.drop([88,89], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start\n",
    "#Load Assessors Parcel Data 2019 CSV & Create dataframe\n",
    "csv_file = \"data/Assessors_Parcel_Data_2019.csv\"\n",
    "assessors_df = pd.read_csv(csv_file)\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with select columns\n",
    "assessors_df = assessors_df[['NEIGHBORHOOD', \n",
    "                                    'FORMATTED_ADDRESS',\n",
    "                                   'PROPERTY_TYPE',\n",
    "                                   'LANDUSE',\n",
    "                                   'TOTALVALUE',\n",
    "                                   'BELOWGROUNDAREA',\n",
    "                                   'ABOVEGROUNDAREA',\n",
    "                                   'BEDROOMS',\n",
    "                                   'PARCEL_AREA_SQFT',\n",
    "                                   'X',\n",
    "                                   'Y']]\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "assessors_parcel_df = assessors_df.rename(columns={\"NEIGHBORHOOD\":\"neighborhood\",\n",
    "                                                   \"FORMATTED_ADDRESS\": \"address\",\n",
    "                                                    \"PROPERTY_TYPE\": \"property_type\",\n",
    "                                                    \"LANDUSE\": \"landuse\",\n",
    "                                                    \"TOTALVALUE\":\"value_total\",\n",
    "                                                    \"BELOWGROUNDAREA\": \"below_grade_sq_footage\",\n",
    "                                                    \"ABOVEGROUNDAREA\": \"above_grade_sq_footage\",\n",
    "                                                    \"BEDROOMS\": \"num_bedrooms\",\n",
    "                                                    \"PARCEL_AREA_SQFT\": \"sq_footage_parcel\",\n",
    "                                                    \"X\": \"x\",\n",
    "                                                    \"Y\": \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out landuse categories that are not residential\n",
    "residential_assessors_df = assessors_parcel_df[(assessors_parcel_df.landuse =='SINGLE-FAMILY DETACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='SINGLE-FAMILY ATTACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY RESIDENTIAL')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY APARTMENT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out property types categories that are not residential\n",
    "residential_df = residential_assessors_df[(residential_assessors_df.property_type =='Residential')\n",
    "                |(residential_assessors_df.property_type =='Condominium')\n",
    "                |(residential_assessors_df.property_type =='Double Bungalow')\n",
    "                |(residential_assessors_df.property_type =='Apartment')\n",
    "                |(residential_assessors_df.property_type =='Cooperative')\n",
    "                |(residential_assessors_df.property_type =='Townhouse')\n",
    "                |(residential_assessors_df.property_type =='Triplex')\n",
    "                |(residential_assessors_df.property_type =='Residential - Zero Lot Line- DB')\n",
    "                |(residential_assessors_df.property_type =='Residential Lake Shore')]                \n",
    "\n",
    "residential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat/lng data based on address - planned to do this but it is cost prohibitive given the $0 budget for this\n",
    "# project and the cost of querying the Google Geocoding API for ~130,000 addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start\n",
    "#Loading data for police incidents and creating a dataframe for the data\n",
    "csv_file = \"data/Police_Incidents_2019.csv\"\n",
    "police_incidents_df = pd.read_csv(csv_file)\n",
    "police_incidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end\n",
    "#Create new dataframe with certain columns\n",
    "incidents_df = police_incidents_df[['description',\n",
    "                                    'neighborhood',\n",
    "                                    'centerLat',\n",
    "                                    'centerLong'\n",
    "                                    ]]\n",
    "incidents_df\n",
    "incidents_df.rename(columns = {'centerLat':\"Latitude\",'centerLong':\"Longitude\"},inplace = True)\n",
    "incidents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to transform all the data\n",
    "1. Lower-case the neighborhood names on both dfs\n",
    "2. Merge dfs on neighborhood names (into new crime df)\n",
    "3. Drop neighborhood name from new crime df\n",
    "4. Do same merge and neighborhood drop on assessor df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.neighborhood = neighborhoods.neighborhood.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Katrina start\n",
    "incidents_df.neighborhood = incidents_df.neighborhood.str.lower()\n",
    "incidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end\n",
    "#join crimes table with neighborhood to get neighborhood ids in crime table\n",
    "#use neighborhoods dataframe at the top of the notebook, neighborhoods is inner join\n",
    "merge_table = pd.merge(neighborhoods, incidents_df, on = \"neighborhood\", how = \"outer\")\n",
    "merge_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods df into database table\n",
    "neighborhoods.to_sql(name='neighborhood', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that data is loaded into postgres\n",
    "pd.read_sql_query('select * from neighborhood', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling it all together in an SQLalchemy query/pandas df for aggregate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

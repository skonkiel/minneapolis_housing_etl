{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies go here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Float \n",
    "from config import pw\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the `minneapolis_housing` database and related tables in Postgresql, using SQLalchemy:\n",
    "\n",
    "* `neighborhood`\n",
    "* `home_value`\n",
    "* `crime`\n",
    "\n",
    "Code for setting up the tables directly in Postgres can be found in the queries.sql file accompanying this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = f\"postgres:{pw}@localhost:5432/minneapolis_housing\"\n",
    "engine = create_engine(f'postgresql://{conn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables if they exist\n",
    "# Neighborhood.__table__.drop(engine)\n",
    "# Crime.__table__.drop(engine)\n",
    "# Home_Value.__table__.drop(engine)\n",
    "# OR \n",
    "# Base.metadata.drop_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base for later creating neighborhood table\n",
    "class Neighborhood(Base):\n",
    "    __tablename__ = 'neighborhood'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood = Column(String(255))\n",
    "    population_2010 = Column(Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base for later creating crime table\n",
    "class Crime(Base):\n",
    "    __tablename__ = 'crime'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood_id = Column(Integer)\n",
    "    crime_description = Column(String(255))\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Home_Value(Base):\n",
    "    __tablename__ = 'home_value'\n",
    "    __table_args__ = {'extend_existing': True} \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    neighborhood_id = Column(Integer)\n",
    "    property_type = Column(String(255))\n",
    "    num_bedrooms = Column(Integer)\n",
    "    sq_footage_house = Column(Integer)\n",
    "    sq_footage_parcel = Column(Integer)\n",
    "    address = Column(String(255))\n",
    "    landuse = Column(String(255))\n",
    "    value_total = Column(Integer)\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "### Neighborhood datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis city dataset for neighborhoods\n",
    "n_path = os.path.join('.', 'data', 'Minneapolis_Neighborhoods.csv')\n",
    "neighborhood = pd.read_csv(n_path)\n",
    "neighborhood_df = neighborhood[['FID', 'BDNAME']].copy()\n",
    "neighborhood_df.rename(columns={\n",
    "    'FID': 'id',\n",
    "    'BDNAME': 'neighborhood'\n",
    "}, inplace=True)\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "Noticed there wasn't a codebook that explained what the cryptic column names mean, so used FID based on the fact\n",
    "that it is a unique ID.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis neighborhood census dataset \n",
    "census_path = os.path.join('.', 'data', 'census_2010.xls')\n",
    "census = pd.read_excel(census_path, header=None)\n",
    "census_df = census.iloc[6:, :2]\n",
    "census_df.rename(columns={\n",
    "    0: 'neighborhood',\n",
    "    1: 'population_2010'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dfs together into one neighborhood df\n",
    "neighborhoods = neighborhood_df.merge(census_df, how='outer', on='neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for null values\n",
    "mask = pd.isnull(neighborhoods.id)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "mask = pd.isnull(neighborhoods.population_2010)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "# No population data for South Uptown (44) or Kenwood (74)\n",
    "# No ids for CARAG (87) or Kenwood (88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with null values \n",
    "\n",
    "# Kenwood (74) should be updated with Kenwood (88)'s pop data \n",
    "neighborhoods.loc[73, 'population_2010'] = neighborhoods.loc[88, 'population_2010']\n",
    "neighborhoods.tail(20)\n",
    "\n",
    "# create id for CARAG (87)\n",
    "neighborhoods.loc[87, 'id'] = '88'\n",
    "\n",
    "# Drop rows 88, 89\n",
    "neighborhoods.drop([88,89], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Assessors Parcel Data 2019 CSV & Create dataframe\n",
    "csv_file = \"data/Assessors_Parcel_Data_2019.csv\"\n",
    "assessors_df = pd.read_csv(csv_file)\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with select columns\n",
    "assessors_df = assessors_df[['NEIGHBORHOOD',\n",
    "                            'PROPERTY_TYPE',\n",
    "                             'BEDROOMS',\n",
    "                             'BELOWGROUNDAREA',\n",
    "                             'ABOVEGROUNDAREA',\n",
    "                             'PARCEL_AREA_SQFT',\n",
    "                             'FORMATTED_ADDRESS',\n",
    "                             'LANDUSE',\n",
    "                             'TOTALVALUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "assessors_parcel_df = assessors_df.rename(columns={\"NEIGHBORHOOD\":\"neighborhood\",\n",
    "                                                   \"FORMATTED_ADDRESS\": \"address\",\n",
    "                                                    \"PROPERTY_TYPE\": \"property_type\",\n",
    "                                                    \"LANDUSE\": \"landuse\",\n",
    "                                                    \"TOTALVALUE\":\"value_total\",\n",
    "                                                    \"BELOWGROUNDAREA\": \"below_grade_sq_footage\",\n",
    "                                                    \"ABOVEGROUNDAREA\": \"above_grade_sq_footage\",\n",
    "                                                    \"BEDROOMS\": \"num_bedrooms\",\n",
    "                                                    \"PARCEL_AREA_SQFT\": \"sq_footage_parcel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nulls\n",
    "assessors_parcel_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently nulls are in below_grade_sq_foot and above_sq_foot columns likely because not \n",
    "#every property has either an above ground level or a basement level\n",
    "#Also, not every property has a bedroom (ex: studios), so replaced those nulls with zeros\n",
    "assessors_parcel_df['below_grade_sq_footage'] = assessors_parcel_df['below_grade_sq_footage'].fillna(0)\n",
    "assessors_parcel_df['above_grade_sq_footage'] = assessors_parcel_df['above_grade_sq_footage'].fillna(0)\n",
    "assessors_parcel_df['num_bedrooms'] = assessors_parcel_df['num_bedrooms'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out landuse categories that are not residential\n",
    "residential_assessors_df = assessors_parcel_df[(assessors_parcel_df.landuse =='SINGLE-FAMILY DETACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='SINGLE-FAMILY ATTACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY RESIDENTIAL')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY APARTMENT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_assessors_df[\"property_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out property types categories that are not residential\n",
    "residential_df = residential_assessors_df[(residential_assessors_df.property_type =='Residential')\n",
    "                |(residential_assessors_df.property_type =='Condominium')\n",
    "                |(residential_assessors_df.property_type =='Double Bungalow')\n",
    "                |(residential_assessors_df.property_type =='Apartment')\n",
    "                |(residential_assessors_df.property_type =='Cooperative')\n",
    "                |(residential_assessors_df.property_type =='Townhouse')\n",
    "                |(residential_assessors_df.property_type =='Triplex')\n",
    "                |(residential_assessors_df.property_type =='Residential - Zero Lot Line- DB')\n",
    "                |(residential_assessors_df.property_type =='Residential Lake Shore')]                \n",
    "\n",
    "residential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat/lng data based on address - planned to do this but it is cost prohibitive given the $0 budget for this\n",
    "# project and the cost of querying the Google Geocoding API for ~130,000 addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start\n",
    "#Loading data for police incidents and creating a dataframe for the data\n",
    "csv_file = \"data/Police_Incidents_2019.csv\"\n",
    "police_incidents_df = pd.read_csv(csv_file)\n",
    "police_incidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end\n",
    "#Create new dataframe with certain columns\n",
    "incidents_df = police_incidents_df[['description',\n",
    "                                    'neighborhood',\n",
    "                                    'X',\n",
    "                                    'Y']]\n",
    "incidents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to transform all the data\n",
    "1. Lower-case the neighborhood names on both dfs\n",
    "2. Merge dfs on neighborhood names (into new crime df)\n",
    "3. Drop neighborhood name from new crime df\n",
    "4. Do same merge and neighborhood drop on assessor df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.neighborhood = neighborhoods.neighborhood.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculated Columns sq_footage_house, value_per_sq_foot, value_per_bedroom\n",
    "#Calculating total square footage\n",
    "sq_footage_house = residential_df['below_grade_sq_footage'] + residential_df['above_grade_sq_footage']\n",
    "\n",
    "residential_df[\"sq_footage_house\"] = residential_df['below_grade_sq_footage'] + \\\n",
    "    residential_df['above_grade_sq_footage']\n",
    "\n",
    "#Calculating value per square foot\n",
    "value_per_sq_foot = residential_df['value_total']/residential_df['sq_footage_house']\n",
    "\n",
    "residential_df[\"value_per_sq_foot\"] = residential_df['value_total']/\\\n",
    "    residential_df['sq_footage_house']\n",
    "\n",
    "\n",
    "residential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change neighborhoods to lowercase\n",
    "residential_df.neighborhood = residential_df.neighborhood.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge on neighborhoods and removed the neighborhood name\n",
    "residential = residential_df.merge(neighborhoods, how='inner', on='neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop neighborhood & population columns\n",
    "residential_final = residential.drop(columns=['neighborhood', 'population_2010'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_final =  residential_final.rename(columns={\"id\":\"neighborhood_id\"})\n",
    "residential_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['num_bedrooms', 'below_grade_sq_footage', 'above_grade_sq_footage', \n",
    "        'sq_footage_house','neighborhood_id']\n",
    "\n",
    "for col in cols:\n",
    "    residential_final[col] = residential_final[col].astype(\"int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods df into database table\n",
    "neighborhoods.to_sql(name='neighborhood', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that data is loaded into postgres\n",
    "pd.read_sql_query('select * from neighborhood', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling it all together in an SQLalchemy query/pandas df for aggregate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies go here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "#from config import pw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the `minneapolis_housing` database and related tables in Postgresql:\n",
    "\n",
    "* `neighborhood`\n",
    "* `home_value`\n",
    "* `crime`\n",
    "\n",
    "Code for setting up the tables can be found in the queries.sql file accompanying this notebook.\n",
    "\n",
    "**Note: Refactor this to work with SQLAlchemy, if time permits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "### Neighborhood datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis city dataset for neighborhoods\n",
    "n_path = os.path.join('.', 'data', 'Minneapolis_Neighborhoods.csv')\n",
    "neighborhood = pd.read_csv(n_path)\n",
    "neighborhood_df = neighborhood[['FID', 'BDNAME']].copy()\n",
    "neighborhood_df.rename(columns={\n",
    "    'FID': 'id',\n",
    "    'BDNAME': 'neighborhood'\n",
    "}, inplace=True)\n",
    "neighborhood_df.set_index('id', inplace=True)\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "Noticed there wasn't a codebook that explained what the cryptic column names mean, so used FID based on the fact\n",
    "that it is a unique ID.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNCompass Minneapolis neighborhood dataset \n",
    "c_path = os.path.join('.', 'data', 'MSP Neighborhoods_2013-2017.csv')\n",
    "compass = pd.read_csv(c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start\n",
    "#Load Assessors Parcel Data 2019 CSV & Create dataframe\n",
    "csv_file = \"data/Assessors_Parcel_Data_2019.csv\"\n",
    "assessors_df = pd.read_csv(csv_file)\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with select columns\n",
    "assessors_df = assessors_df[['NEIGHBORHOOD', \n",
    "                                    'FORMATTED_ADDRESS',\n",
    "                                   'PROPERTY_TYPE',\n",
    "                                   'LANDUSE',\n",
    "                                   'TOTALVALUE',\n",
    "                                   'BELOWGROUNDAREA',\n",
    "                                   'ABOVEGROUNDAREA',\n",
    "                                   'BEDROOMS',\n",
    "                                   'PARCEL_AREA_SQFT',\n",
    "                                   'X',\n",
    "                                   'Y']]\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "assessors_parcel_df = assessors_df.rename(columns={\"NEIGHBORHOOD\":\"neighborhood\",\n",
    "                                                   \"FORMATTED_ADDRESS\": \"address\",\n",
    "                                                    \"PROPERTY_TYPE\": \"property_type\",\n",
    "                                                    \"LANDUSE\": \"landuse\",\n",
    "                                                    \"TOTALVALUE\":\"value_total\",\n",
    "                                                    \"BELOWGROUNDAREA\": \"below_grade_sq_footage\",\n",
    "                                                    \"ABOVEGROUNDAREA\": \"above_grade_sq_footage\",\n",
    "                                                    \"BEDROOMS\": \"num_bedrooms\",\n",
    "                                                    \"PARCEL_AREA_SQFT\": \"sq_footage_parcel\",\n",
    "                                                    \"X\": \"x\",\n",
    "                                                    \"Y\": \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out landuse categories that are not residential\n",
    "residential_assessors_df = assessors_parcel_df[(assessors_parcel_df.landuse =='SINGLE-FAMILY DETACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='SINGLE-FAMILY ATTACHED DWELLING')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY RESIDENTIAL')\n",
    "                            |(assessors_parcel_df.landuse =='MULTI-FAMILY APARTMENT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out property types categories that are not residential\n",
    "residential_df = residential_assessors_df[(residential_assessors_df.property_type =='Residential')\n",
    "                |(residential_assessors_df.property_type =='Condominium')\n",
    "                |(residential_assessors_df.property_type =='Double Bungalow')\n",
    "                |(residential_assessors_df.property_type =='Apartment')\n",
    "                |(residential_assessors_df.property_type =='Cooperative')\n",
    "                |(residential_assessors_df.property_type =='Townhouse')\n",
    "                |(residential_assessors_df.property_type =='Triplex')\n",
    "                |(residential_assessors_df.property_type =='Residential - Zero Lot Line- DB')\n",
    "                |(residential_assessors_df.property_type =='Residential Lake Shore')]                \n",
    "\n",
    "residential_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

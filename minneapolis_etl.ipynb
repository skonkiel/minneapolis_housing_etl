{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies go here\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from config import pw\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the `minneapolis_housing` database and related tables in Postgresql:\n",
    "\n",
    "* `neighborhood`\n",
    "* `home_value`\n",
    "* `crime`\n",
    "\n",
    "Code for setting up the tables can be found in the queries.sql file accompanying this notebook.\n",
    "\n",
    "**Note: Refactor this to work with SQLAlchemy, if time permits**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "### Neighborhood datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis city dataset for neighborhoods\n",
    "n_path = os.path.join('.', 'data', 'Minneapolis_Neighborhoods.csv')\n",
    "neighborhood = pd.read_csv(n_path)\n",
    "neighborhood_df = neighborhood[['FID', 'BDNAME']].copy()\n",
    "neighborhood_df.rename(columns={\n",
    "    'FID': 'id',\n",
    "    'BDNAME': 'neighborhood'\n",
    "}, inplace=True)\n",
    "\n",
    "'''\n",
    "NOTES:\n",
    "Noticed there wasn't a codebook that explained what the cryptic column names mean, so used FID based on the fact\n",
    "that it is a unique ID.\n",
    "'''\n",
    "neighborhood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Minneapolis neighborhood census dataset \n",
    "census_path = os.path.join('.', 'data', 'census_2010.xls')\n",
    "census = pd.read_excel(census_path, header=None)\n",
    "census_df = census.iloc[6:, :2]\n",
    "census_df.rename(columns={\n",
    "    0: 'neighborhood',\n",
    "    1: 'population_2010'\n",
    "}, inplace=True)\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dfs together into one neighborhood df\n",
    "neighborhoods = neighborhood_df.merge(census_df, how='outer', on='neighborhood')\n",
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for null values\n",
    "\n",
    "mask = pd.isnull(neighborhoods.id)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "mask = pd.isnull(neighborhoods.population_2010)\n",
    "print(neighborhoods[mask])\n",
    "\n",
    "# No population data for South Uptown (44) or Kenwood (74)\n",
    "# No ids for CARAG (87) or Kenwood (88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with null values \n",
    "\n",
    "# Kenwood (74) should be updated with Kenwood (88)'s pop data \n",
    "neighborhoods.loc[73, 'population_2010'] = neighborhoods.loc[88, 'population_2010']\n",
    "neighborhoods.tail(20)\n",
    "\n",
    "# create id for CARAG (87)\n",
    "neighborhoods.loc[87, 'id'] = '88'\n",
    "\n",
    "# Drop rows 88, 89\n",
    "neighborhoods.drop([88,89], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start\n",
    "#Load Assessors Parcel Data 2019 CSV & Create dataframe\n",
    "csv_file = \"data/Assessors_Parcel_Data_2019.csv\"\n",
    "assessors_df = pd.read_csv(csv_file)\n",
    "assessors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with select columns\n",
    "assessors_parcel_df = assessors_df[['NEIGHBORHOOD', \n",
    "                                    'FORMATTED_ADDRESS',\n",
    "                                   'PROPERTY_TYPE',\n",
    "                                   'LANDUSE',\n",
    "                                   'TOTALVALUE',\n",
    "                                   'BELOWGROUNDAREA',\n",
    "                                   'ABOVEGROUNDAREA',\n",
    "                                   'BEDROOMS',\n",
    "                                   'PARCEL_AREA_SQFT',\n",
    "                                   'X',\n",
    "                                   'Y']]\n",
    "assessors_parcel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out property types that are not residential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start\n",
    "#Loading data for police incidents and creating a dataframe for the data\n",
    "csv_file = \"data/Police_Incidents_2019.csv\"\n",
    "police_incidents_df = pd.read_csv(csv_file)\n",
    "police_incidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end\n",
    "#Create new dataframe with certain columns\n",
    "incidents_df = police_incidents_df[['description',\n",
    "                                    'neighborhood',\n",
    "                                    'X',\n",
    "                                    'Y']]\n",
    "incidents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to transform all the data\n",
    "1. Lower-case the neighborhood names on both dfs\n",
    "2. Merge dfs on neighborhood names (into new crime df)\n",
    "3. Drop neighborhood name from new crime df\n",
    "4. Do same merge and neighborhood drop on assessor df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.neighborhood = neighborhoods.neighborhood.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jenna end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katrina end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = f\"postgres:{pw}@localhost:5432/minneapolis_housing\"\n",
    "engine = create_engine(f'postgresql://{conn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods df into database table\n",
    "neighborhoods.to_sql(name='neighborhood', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that data is loaded into postgres\n",
    "pd.read_sql_query('select * from neighborhood', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling it all together in an SQLalchemy query/pandas df for aggregate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
